# pyHadith

[![GPLv3 License](https://img.shields.io/badge/License-GPL%20v3-yellow.svg)](https://opensource.org/licenses/) 
[![PyUp](https://pyup.io/repos/github/umarbutler/pyhadith/shield.svg)](https://pyup.io/account/repos/github/umarbutler/pyhadith/yt2mp3/) 
[![PyPi Version](https://img.shields.io/pypi/v/pyhadith.svg)](https://pypi.python.org/pypi/pyhadith/) 
[![Python Versions](https://img.shields.io/pypi/pyversions/yt2mp3.svg)](https://pypi.python.org/pypi/yt2mp3/)

pyHadith is a python package which automatically segments, categorizes and reconstructs the asnad of, ahadith.

The package works by feeding raw text to custom natural language processing (NLP) models and algorithms. The resulting data is the aggregated and returned in a standardized format.

## 1. How It Works

### 1.1. Statistical Natural Language Processing Models

pyHadith uses three statistical natural language processing (NLP) models to deconstruct and analyze ahadith. These are: a Named Entity Recognition (NER) model, known as *rawa*, which extracts the names of narrators; a Named Entity Recognition (NER) model, known as *hawiya*, which standardizes the identities of narrators, assigning them unique IDs; and, a Text Classification model, known as *asl*, which categorizes ahadith as either [athar](https://en.wikipedia.org/wiki/Hadith#Distinction_from_other_literature) or [khabar](https://en.wikipedia.org/wiki/Hadith#Distinction_from_other_literature).

While both the *rawa* and *asl* models require the passing of an entire hadith, the *hawiya* model only requires an isnad.

All of the models were trained on manually annotated ahadith by the Saudi Arabian *[Permanent Committee for Scholarly Research and Ifta](https://sunnah.alifta.gov.sa/)*. Due to copyright, the data used to train the models cannot be reproduced. The models themselves, however, are not copyrighted (except under our own GNU GPLv3 license) as they come under the fair use doctrine.

The models were generated by [spaCy](https://spacy.io/) version 2.2.4.

The *rawa* and *asl* models were trained on a corpus containing 29,288 annotated ahadith, taken from [sunnah.alifta.gov.sa](https://sunnah.alifta.gov.sa/). 5,784 ahadith were withheld and used for evaluating models.

The *hawiya* model was trained on a corpus containing X annotated ahadith, again taken from [sunnah.alifta.gov.sa](https://sunnah.alifta.gov.sa/). X ahadith were withheld for evaluation.

After training models for 100 iterations, the best performing models were selected.

The scores of the final models are displayed in the table below:

| Model | Model Type | Precision | Recall | F-Score |
|--|--|--|--|--|
| Rawa  | Named Entity Recognition | 98.96 | 98.91 | 98.94 |
| Asl   | Text Classification |  |  | 97.78 |

### 1.2. Pre-Processor

Before a hadith is passed to a spaCy model, it is first 'cleaned' by a pre-processor.

The pre-processor strips away punctuation and extra white space.

The pre-processor also uses [Motaz Saad](https://github.com/motazsaad)'s '[split-waw-arabic](https://github.com/motazsaad/split-waw-arabic)' method to identify and add whitespaces after the word 'وَ'. This is necessary to differentiate between the letter 'و‎' and the word 'وَ' (meaning 'and'), which is joined to words.

### 1.3. Rawa Post-Processor

To ensure that the names extracted by the *rawa* model are accurate, a post-processor looks for common joining terms at the beginning of each name. If a common joining term is found, it is removed from the name.

### 1.4. Hadith Deconstruction Algorithm

To deconstruct a hadith into a matn and an isnad, a custom algorithm is employed. The algorithm assumes that a matn has begun at the final occurrence of a narrator's name (identified by the *rawa* model). Everything before the matn is classed as the isnad.

### 1.5. Asnad Reconstruction Algorithm

An Asnad Reconstruction algorithm is employed to standardize narrational relationships in a tree-like data structure.

There are two possible relationships recognized by the algorithm: A **from** B, and, A **from** B **and** C. Thus, where a term joins two or more narrators to a single narratee, that narratee will have multiple 'parent' narrators. Multiple 'parents' are identified by looking for the arabic word 'وَ'.

## 2. Installation

pyHadith is available on pip. You can install pyHadith using the following command:

    pip install pyHadith

The following python packages will also be automatically installed as dependencies of pyHadith:

| Package | Version | Description |
|--|--|--|
| [spaCy](https://github.com/explosion/spaCy) | 2.2.4 | Used to interact with the *rawa* and *asl* models.
| [pyArabic](https://github.com/linuxscout/pyarabic) | >= 0.6.7 | Used to remove diacritics from arabic strings.
| [nltk](https://github.com/nltk/nltk) | >= 3.4.5 | Used to tokenize arabic strings.

## 3. Usage

### 3.1. Import pyHadith

The first step in using pyHadith is to import the package to your code. You can do so with the following line:

    # Import the pyHadith package.
    import pyHadith

### 3.2. Deconstruct a Hadith

To deconstruct a hadith, you must first create a 'hadith' object with the hadith module. This requires the passing of a single argument, a UTF-8 encoded Arabic text with diacritics.

The code below demonstrates how a 'hadith' object can be created:

    # Continue on from example code in 3.1.
    # Set the hadith to be processed.
    text = u'حَدَّثَنِي يَحْيَى، عَنْ مَالِكٍ، أَنَّهُ بَلَغَهُ أَنَّ سَعِيدَ بْنَ الْمُسَيَّبِ، وَسُلَيْمَانَ بْنَ يَسَارٍ، كَانَا يَقُولاَنِ عِدَّةُ الأَمَةِ إِذَا هَلَكَ عَنْهَا زَوْجُهَا شَهْرَانِ وَخَمْسُ لَيَالٍ ‏.‏'
    # Create a hadith object using the text of the hadith.
    x = hadith.Hadith(text)
    # Print the resulting attributes.
    print({
    "raw" : x.raw,
    "clean" : x.clean,
    "matn" : x.matn,
    "isnad" : x.isnad,
    "category" : x.category
    })

Once a hadith object is created, the following attributes will become available:

| Attribute | Data Type | Description |
|--|--|--|
| raw | String | The original raw text. |
| clean | String | The cleaned raw text. |
| matn | Object | An object containing the 'raw' text, 'start_char' index (in the cleaned text), and 'end_char' index (in the cleaned text), of the matn. |
| isnad | Object | An object containing the 'raw' text, 'start_char' index (in the cleaned text), and 'end_char' index (in the cleaned text), of the isnad, along with a 'narrators' list which contains narrator objects (discussed later). |
| category | Object | An object containing the 'label' (either 'athar' or 'khabar') and 'score' (from .5 to 1) of the assigned category. |

A 'narrator' object in the 'narrators' list will contain the following attributes:

| Attribute | Data Type | Description |
|--|--|--|
| id | Integer | A unique identifier number. |
| name | String | The raw text of the narrator's name. |
| start_char | Integer | The character index in the cleaned text where the name begins. |
| end_char | Integer | The character index in the cleaned text where the name ends. |
| parents | List | A list of the ids of the narrator's parents within the isnad. |

## 4. License

pyHadith is licensed under [GPLv3](https://github.com/umarbutler/pyhadith/blob/master/LICENSE). pyArabic, spaCy and NLTK are licensed under [GPLv3](https://github.com/linuxscout/pyarabic/blob/master/LICENSE), [MIT](https://github.com/explosion/spaCy/blob/master/LICENSE), and [Apache 2.0](https://github.com/nltk/nltk/blob/develop/LICENSE.txt), respectively. These licenses are all GPL compatible.
